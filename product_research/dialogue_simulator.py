
import os
import re
import json
import time
import argparse
import subprocess
from typing import Optional, Tuple, List, Dict, Any
from urllib import request, error as urlerror

# ============================================================
# –¢–ï–ö–°–¢–û–í–´–ï –£–¢–ò–õ–ò–¢–´
# ============================================================

ROLE_PREFIX_RE = re.compile(r"^\s*(–û–ø–µ—Ä–∞—Ç–æ—Ä|–ú–µ–Ω–µ–¥–∂–µ—Ä|–ö–ª–∏–µ–Ω—Ç|Manager|Operator|Client)\s*[:\-‚Äì]\s*", re.IGNORECASE)
BULLET_RE = re.compile(r"^\s*[\-\*\‚Ä¢]+\s*")
WS_RE = re.compile(r"\s+")

# –†–∞–∑—Ä–µ—à–∞–µ–º: —Ä—É—Å—Å–∫–∏–µ, –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ, —Ü–∏—Ñ—Ä—ã, –±–∞–∑–æ–≤–∞—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è, –ø—Ä–æ–±–µ–ª—ã
# + –¥–æ–±–∞–≤–∏–ª–∏ ‚Äú‚Ä¶‚Äù –∏ ‚Äú‚Ññ‚Äù (—á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ —Ä—É—Å—Å–∫–æ–º, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ª–æ–∂–Ω—ã—Ö NON_RU)
ALLOWED_BASIC_RE = re.compile(
    r"[^–ê-–Ø–∞-—è–Å—ëA-Za-z0-9,.;:!?()\"'¬´¬ª‚Äú‚Äù‚Äû\-\s/&_+%#‚Ä¶‚Ññ]"
)

# –ë—ã—Å—Ç—Ä—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä "—á—É–∂–∏—Ö" —Å–∏–º–≤–æ–ª–æ–≤ (CJK/–∞—Ä–∞–±—Å–∫–∏–π –∏ —Ç.–ø.) ‚Äî —Ç–∞–∫–∂–µ —Ä–∞–∑—Ä–µ—à–∞–µ–º ‚Ä¶ –∏ ‚Ññ
NON_RU_EN_LETTER_RE = re.compile(
    r"[^\s–ê-–Ø–∞-—è–Å—ëA-Za-z0-9,.;:!?()\"'¬´¬ª‚Äú‚Äù‚Äû\-\s/&_+%#‚Ä¶‚Ññ]"
)

def normalize_text_line(text: str) -> str:
    if not text:
        return ""
    replacements = {
        "‚Äú": '"', "‚Äù": '"', "‚Äû": '"', "¬´": '"', "¬ª": '"',
        "‚Äô": "'", "‚Äò": "'",
        "‚Äî": "-", "‚Äì": "-",
        "\u00a0": " ",  # non-breaking space
        "‚Ä¶": "...",     # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ
    }
    for src, dst in replacements.items():
        text = text.replace(src, dst)
    text = text.replace("\r", " ").replace("\n", " ")
    text = WS_RE.sub(" ", text)
    return text.strip()

def clean_manager_input(raw: str) -> str:
    if not raw:
        return ""
    text = raw.strip()
    text = ROLE_PREFIX_RE.sub("", text)
    return normalize_text_line(text)

def _trim_to_sentence_boundary(text: str, max_chars: int) -> str:
    """–†–µ–∂–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö max_chars (—á—Ç–æ–±—ã –Ω–µ –æ–±—Ä—É–±–∞—Ç—å –º—ã—Å–ª—å)."""
    if not text or max_chars <= 0:
        return ""
    if len(text) <= max_chars:
        return text

    cut = text[:max_chars].rstrip()

    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    last_end = max(cut.rfind("."), cut.rfind("!"), cut.rfind("?"))

    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–ª–µ–∫–æ (>= 55% –ª–∏–º–∏—Ç–∞), —Ä–µ–∂–µ–º —Ç–∞–º.
    if last_end >= max(0, int(max_chars * 0.55)):
        return cut[: last_end + 1].strip()

    # –ò–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ –º—è–≥–∫–æ –æ–±—Ä–µ–∂–µ–º –ø–æ —Å–∏–º–≤–æ–ª–∞–º (–ª—É—á—à–µ —á–µ–º –ø—É—Å—Ç–æ).
    return cut.strip()

def clean_reply(raw: str, max_sentences: int = 5, reply_max_chars: int = 320) -> str:
    """
    1) –≤—ã—á–∏—â–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å—ã —Ä–æ–ª–µ–π/–±—É–ª–ª–µ—Ç—ã
    2) –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç
    3) —É–¥–∞–ª—è–µ—Ç "—Å—Ç—Ä–∞–Ω–Ω—ã–µ" —Å–∏–º–≤–æ–ª—ã, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç RU+EN (–±—Ä–µ–Ω–¥—ã)
    4) –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º (–ø–æ –≥—Ä–∞–Ω–∏—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
    """
    if not raw:
        return ""
    text = raw.strip()
    text = ROLE_PREFIX_RE.sub("", text)
    text = BULLET_RE.sub("", text)
    text = normalize_text_line(text)

    # –≤—ã–∫–∏–¥—ã–≤–∞–µ–º —Å–æ–≤—Å–µ–º "–ª–µ–≤—ã–µ" —Å–∏–º–≤–æ–ª—ã, –Ω–æ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º A-Za-z (Google Sheets/Excel)
    text = ALLOWED_BASIC_RE.sub(" ", text)
    text = WS_RE.sub(" ", text).strip()
    if not text:
        return ""

    # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
    parts = re.split(r"(?<=[.!?])\s+", text)
    if parts:
        text = " ".join(parts[:max_sentences]).strip()

    # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Å–∏–º–≤–æ–ª–∞–º (–ø–æ –≥—Ä–∞–Ω–∏—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
    text = _trim_to_sentence_boundary(text, reply_max_chars)
    return text

def has_non_ru_en_garbage(text: str) -> bool:
    """True –µ—Å–ª–∏ –µ—Å—Ç—å —Å–∏–º–≤–æ–ª—ã –≤–Ω–µ RU/EN/—Ü–∏—Ñ—Ä/–±–∞–∑–æ–≤–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏."""
    if not text:
        return True
    return bool(NON_RU_EN_LETTER_RE.search(text))

def raw_has_non_ru_en_garbage(raw: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –º—É—Å–æ—Ä–∞ –Ω–∞ —Å—ã—Ä–æ–º —Ç–µ–∫—Å—Ç–µ (–¥–æ —á–∏—Å—Ç–∫–∏), —á—Ç–æ–±—ã —Ä–µ—Ç—Ä–∞–∏ —Ä–µ–∞–ª—å–Ω–æ –∏–º–µ–ª–∏ —Å–º—ã—Å–ª."""
    if not raw:
        return True
    t = raw.strip()
    t = ROLE_PREFIX_RE.sub("", t)
    t = normalize_text_line(t)
    return bool(NON_RU_EN_LETTER_RE.search(t))

# ============================================================
# –ü–†–ò–ë–õ–ò–ñ–Å–ù–ù–ê–Ø –û–¶–ï–ù–ö–ê –¢–û–ö–ï–ù–û–í
# ============================================================

def _approx_tokens_ru(text: str) -> int:
    if not text:
        return 0
    t = normalize_text_line(text)
    words = re.findall(r"\w+", t, flags=re.UNICODE)
    by_words = len(words)
    by_chars = max(1, int(len(t) / 4))
    return max(1, int((by_words + by_chars) / 2))

# ============================================================
# –ú–ï–¢–†–ò–ö–ò
# ============================================================

def summarize_metrics(records: List[Dict[str, Any]]) -> Dict[str, Any]:
    if not records:
        return {"count": 0}

    lat_total = [r["latency_total_s"] for r in records if r.get("latency_total_s") is not None]
    lat_model = [r["latency_model_s"] for r in records if r.get("latency_model_s") is not None]
    out_tok = [r["out_tokens"] for r in records if r.get("out_tokens") is not None]
    in_tok = [r["in_tokens"] for r in records if r.get("in_tokens") is not None]
    tps = [r["tps"] for r in records if r.get("tps") is not None]

    ok = [r for r in records if r.get("err_reason") is None]
    timeouts = sum(1 for r in records if r.get("err_reason") == "TIMEOUT")
    errors = sum(1 for r in records if r.get("err_reason") in ("OLLAMA_ERROR", "HTTP_ERROR"))

    def p50(xs):
        xs = sorted(xs)
        return xs[len(xs)//2] if xs else None

    def avg(xs):
        return (sum(xs) / len(xs)) if xs else None

    return {
        "count": len(records),
        "ok": len(ok),
        "timeouts": timeouts,
        "errors": errors,
        "lat_total_avg": avg(lat_total),
        "lat_total_p50": p50(lat_total),
        "lat_total_min": min(lat_total) if lat_total else None,
        "lat_total_max": max(lat_total) if lat_total else None,
        "lat_model_avg": avg(lat_model),
        "lat_model_p50": p50(lat_model),
        "in_tokens_total": sum(in_tok) if in_tok else 0,
        "out_tokens_total": sum(out_tok) if out_tok else 0,
        "tps_avg": avg(tps),
        "tps_p50": p50(tps),
    }

def print_metrics_summary(records: List[Dict[str, Any]]):
    s = summarize_metrics(records)
    if s["count"] == 0:
        print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        return

    print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ—Å—Å–∏–∏ (–ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω—ã–µ):")
    print(f"- –∑–∞–ø—Ä–æ—Å–æ–≤: {s['count']} | ok: {s['ok']} | timeout: {s['timeouts']} | errors: {s['errors']}")
    if s["lat_total_avg"] is not None:
        print(f"- latency_total (s): avg={s['lat_total_avg']:.2f} | p50={s['lat_total_p50']:.2f} | min={s['lat_total_min']:.2f} | max={s['lat_total_max']:.2f}")
    if s["lat_model_avg"] is not None:
        print(f"- latency_model (s): avg={s['lat_model_avg']:.2f} | p50={s['lat_model_p50']:.2f}")
    print(f"- tokens: in_total={s['in_tokens_total']} | out_total={s['out_tokens_total']}")
    if s["tps_avg"] is not None:
        print(f"- tokens/sec: avg={s['tps_avg']:.2f} | p50={s['tps_p50']:.2f}")

def save_jsonl(records: List[Dict[str, Any]], path: str):
    if not records or not path:
        return
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        for r in records:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

# ============================================================
# –ö–û–ù–§–ò–ì
# ============================================================

ARCHETYPES: Dict[str, Dict[str, Any]] = {
    "novice": {
        "name": "–ù–æ–≤–∏—á–æ–∫",
        "personality": "–Ø —Ç–æ–ª—å–∫–æ –Ω–∞—á–∏–Ω–∞—é, —Ö–æ—á—É –ø—Ä–æ—Å—Ç—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –º–æ–≥—É –ø—É—Ç–∞—Ç—å—Å—è, –Ω–æ –±–µ–∑ –∞–≥—Ä–µ—Å—Å–∏–∏.",
        "speech_style": "–∫–æ—Ä–æ—Ç–∫–æ, –ø–æ –¥–µ–ª—É, –∏–Ω–æ–≥–¥–∞ —É—Ç–æ—á–Ω—è—é –±–∞–∑–æ–≤—ã–µ –≤–µ—â–∏",
        "default_goal": "–ø–æ–Ω—è—Ç—å, —á—Ç–æ —ç—Ç–æ –∏ –Ω—É–∂–Ω–æ –ª–∏ –º–Ω–µ",
        "taboos": ["–Ω–µ –∏–∑–æ–±—Ä–∞–∂–∞–π —ç–∫—Å–ø–µ—Ä—Ç–∞", "–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –±–µ–∑ –ø—Ä–æ—Å—å–±—ã"],
    },
    "skeptic": {
        "name": "–°–∫–µ–ø—Ç–∏–∫",
        "personality": "–ù–µ –¥–æ–≤–µ—Ä—è—é, –∏—â—É –ø–æ–¥–≤–æ—Ö, –Ω–µ –ª—é–±–ª—é –≤–æ–¥—É, —Ç—Ä–µ–±—É—é –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É.",
        "speech_style": "—Å—Ç—Ä–æ–≥–æ, –±–µ–∑ —ç–º–æ—Ü–∏–π, '–ø–æ–∫–∞–∂–∏—Ç–µ —Ü–∏—Ñ—Ä—ã'",
        "default_goal": "–º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∏—Å–∫ –∏ –Ω–µ –ø–æ–ø–∞—Å—Ç—å –Ω–∞ –∫–æ–º–∏—Å—Å–∏–∏",
        "taboos": ["–Ω–µ —Å—Ç–∞–Ω–æ–≤–∏—Å—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º", "–Ω–µ —Å–æ–≥–ª–∞—à–∞–π—Å—è —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ"],
    },
    "busy_owner": {
        "name": "–ó–∞–Ω—è—Ç–æ–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å",
        "personality": "–£ –º–µ–Ω—è –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏, —è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤ –¥–µ–ª–∞—Ö. –ï—Å–ª–∏ —Ç—è–Ω—É—Ç –≤—Ä–µ–º—è ‚Äî —Ä–∞–∑–¥—Ä–∞–∂–∞—é—Å—å.",
        "speech_style": "–∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã, –ø–µ—Ä–µ–±–∏–≤–∞—é, –ø—Ä–æ—à—É —Ç–µ–∑–∏—Å—ã",
        "default_goal": "–±—ã—Å—Ç—Ä–æ –ø–æ–Ω—è—Ç—å –≤—ã–≥–æ–¥—É –∏ —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–π–º—ë—Ç",
        "taboos": ["–Ω–µ —É—Ö–æ–¥–∏ –≤ –¥–ª–∏–Ω–Ω—ã–µ –º–æ–Ω–æ–ª–æ–≥–∏"],
    },
    "friendly": {
        "name": "–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π",
        "personality": "–ù–æ—Ä–º–∞–ª—å–Ω–æ –æ—Ç–Ω–æ—à—É—Å—å –∫ –∑–≤–æ–Ω–∫—É, –≥–æ—Ç–æ–≤ –æ–±—Å—É–¥–∏—Ç—å, –Ω–æ –≤—Å—ë —Ä–∞–≤–Ω–æ —Å—á–∏—Ç–∞—é –¥–µ–Ω—å–≥–∏.",
        "speech_style": "–≤–µ–∂–ª–∏–≤–æ, –±–µ–∑ —Ä–µ–∑–∫–æ—Å—Ç–∏, –∑–∞–¥–∞—é –≤–æ–ø—Ä–æ—Å—ã",
        "default_goal": "–ø–æ–¥–æ–±—Ä–∞—Ç—å —É–¥–æ–±–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
        "taboos": ["–Ω–µ —Å—Ç–∞–Ω–æ–≤–∏—Å—å —Å–ª–∏—à–∫–æ–º '—Å–ª–∞–¥–∫–∏–º'"],
    },
}

DIFFICULTY: Dict[str, Dict[str, Any]] = {
    "1": {"name": "1 ‚Äî –õ—ë–≥–∫–∏–π", "question_rate": "low", "resistance": "low", "traps": False},
    "2": {"name": "2 ‚Äî –ù–æ—Ä–º–∞–ª—å–Ω—ã–π", "question_rate": "medium", "resistance": "medium", "traps": False},
    "3": {"name": "3 ‚Äî –°–ª–æ–∂–Ω—ã–π", "question_rate": "medium", "resistance": "high", "traps": True},
    "4": {"name": "4 ‚Äî –û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π", "question_rate": "high", "resistance": "very_high", "traps": True},
}

PRODUCTS: Dict[str, Dict[str, Any]] = {
    "free": {
        "name": "–°–≤–æ–±–æ–¥–Ω–∞—è —Ç–µ–º–∞",
        "description": "–ë–µ–∑ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤. –ö–ª–∏–µ–Ω—Ç ‚Äî –ª–∏—á–Ω–æ—Å—Ç—å (–∞—Ä—Ö–µ—Ç–∏–ø+—Å–ª–æ–∂–Ω–æ—Å—Ç—å).",
        "facts": [],
        "goal": "",
        "typical_next_steps": [],
    },
    "rko": {
        "name": "–†–ö–û",
        "description": "–†–∞–∑–≥–æ–≤–æ—Ä –ø—Ä–æ —Ä–∞—Å—á—ë—Ç–Ω—ã–π —Å—á—ë—Ç/–∫–æ–º–∏—Å—Å–∏–∏/–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ/–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ.",
        "facts": [
            "–£ –∫–ª–∏–µ–Ω—Ç–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—á—ë—Ç –≤ –¥—Ä—É–≥–æ–º –±–∞–Ω–∫–µ",
            "–ö–ª–∏–µ–Ω—Ç–∞ –≤–æ–ª–Ω—É—é—Ç –∫–æ–º–∏—Å—Å–∏–∏, –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ, –ª–∏–º–∏—Ç—ã, —Å–∫–æ—Ä–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–π",
        ],
        "goal": "–ø–æ–Ω—è—Ç—å –≤—ã–≥–æ–¥—É/—Ä–∏—Å–∫–∏ –∏ —Ä–µ—à–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —Å–º—ã—Å–ª –¥–≤–∏–≥–∞—Ç—å—Å—è –¥–∞–ª—å—à–µ",
        "typical_next_steps": ["–ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—á—ë—Ç —Ç–∞—Ä–∏—Ñ–∞", "–Ω–∞–∑–Ω–∞—á–∏—Ç—å —Å–æ–∑–≤–æ–Ω/–≤—Å—Ç—Ä–µ—á—É", "–æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã"],
    },
    "bank_card": {
        "name": "–ë–∏–∑–Ω–µ—Å-–∫–∞—Ä—Ç–∞",
        "description": "–†–∞–∑–≥–æ–≤–æ—Ä –ø—Ä–æ –∫–∞—Ä—Ç—É, –ª–∏–º–∏—Ç—ã, –∫—ç—à–±—ç–∫, –∫–æ–Ω—Ç—Ä–æ–ª—å —Ä–∞—Å—Ö–æ–¥–æ–≤.",
        "facts": [
            "–ö–ª–∏–µ–Ω—Ç—É –≤–∞–∂–Ω—ã –ª–∏–º–∏—Ç—ã, –∫–æ–º–∏—Å—Å–∏–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
            "–ò–Ω–æ–≥–¥–∞ –Ω—É–∂–Ω–∞ –∫–∞—Ä—Ç–∞ –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤",
        ],
        "goal": "–ø–æ–Ω—è—Ç—å –≤—ã–≥–æ–¥—É –∏ —Å—Ç–æ–∏—Ç –ª–∏ –æ—Ñ–æ—Ä–º–ª—è—Ç—å",
        "typical_next_steps": ["—É—Ç–æ—á–Ω–∏—Ç—å —Ç–∞—Ä–∏—Ñ", "–æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞—è–≤–∫—É", "—Å–æ–∑–≤–æ–Ω –¥–ª—è –¥–µ—Ç–∞–ª–µ–π"],
    },
}

def _list_keys(d: Dict[str, Any]) -> str:
    return ", ".join(sorted(d.keys()))

def resolve_archetype(archetype_id: str) -> Dict[str, Any]:
    return ARCHETYPES.get(archetype_id, {
        "name": archetype_id,
        "personality": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞—Ä—Ö–µ—Ç–∏–ø (fallback). –í–µ–¥–∏ —Å–µ–±—è –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ.",
        "speech_style": "–∫—Ä–∞—Ç–∫–æ",
        "default_goal": "–ø–æ–Ω—è—Ç—å —Å—É—Ç—å",
        "taboos": [],
    })

def resolve_difficulty(level_id: str) -> Dict[str, Any]:
    return DIFFICULTY.get(level_id, {
        "name": level_id, "question_rate": "medium", "resistance": "medium", "traps": False,
    })

def resolve_product(product_id: str) -> Dict[str, Any]:
    return PRODUCTS.get(product_id, {
        "name": product_id, "description": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç (fallback).",
        "facts": [], "goal": "", "typical_next_steps": [],
    })

# ============================================================
# PROMPT (FAST-SAFE)
# ============================================================

def _compact_json_list(xs: List[str]) -> str:
    if not xs:
        return "[]"
    return "[" + "; ".join(xs) + "]"

def build_system_prompt(archetype_id: str, difficulty_id: str, product_id: str) -> str:
    a = resolve_archetype(archetype_id)
    d = resolve_difficulty(difficulty_id)
    p = resolve_product(product_id)

    traps_hint = "–ª–æ–≤—É—à–∫–∏=–¥–∞" if d.get("traps") else "–ª–æ–≤—É—à–∫–∏=–Ω–µ—Ç"
    taboos_line = _compact_json_list(a.get("taboos", []) or [])

    product_line = ""
    if product_id != "free":
        product_line = (
            f"\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {p.get('name')} ({p.get('description')})"
            f"\n–§–∞–∫—Ç—ã: {_compact_json_list(p.get('facts', []) or [])}"
            f"\n–¶–µ–ª—å –∫–ª–∏–µ–Ω—Ç–∞: {p.get('goal','')}"
        )

    # –£—Å–∏–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã: –∑–∞–ø—Ä–µ—Ç –Ω–∞ ‚Äú–∏–Ω—Ç–µ—Ä–≤—å—é –º–µ–Ω–µ–¥–∂–µ—Ä–∞‚Äù
    if archetype_id == "novice":
        initiative_rule = (
            "–ü—Ä–∞–≤–∏–ª–æ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã: –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã ‚Äî –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ø—Ä–æ —Å–µ–±—è/—Å–≤–æ—é –∫–æ–º–ø–∞–Ω–∏—é. "
            "–í–æ–æ–±—â–µ –Ω–µ –∑–∞–¥–∞–≤–∞–π –≤—Å—Ç—Ä–µ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –º–µ–Ω–µ–¥–∂–µ—Ä—É. "
            "–ï—Å–ª–∏ –Ω–µ –ø–æ–Ω—è–ª ‚Äî —Å–∫–∞–∂–∏ '–ù–µ –ø–æ–Ω—è–ª, –ø–æ—è—Å–Ω–∏—Ç–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏' (–±–µ–∑ –≤–æ–ø—Ä–æ—Å–∞ '—É –≤–∞—Å/–≤—ã').\n"
        )
    else:
        initiative_rule = (
            "–ü—Ä–∞–≤–∏–ª–æ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã: –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã ‚Äî –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ø—Ä–æ —Å–µ–±—è/—Å–≤–æ—é –∫–æ–º–ø–∞–Ω–∏—é. "
            "–ù–µ –∑–∞–¥–∞–≤–∞–π –≤—Å—Ç—Ä–µ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –º–µ–Ω–µ–¥–∂–µ—Ä—É. "
            "–ï—Å–ª–∏ –Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ ‚Äî –º–∞–∫—Å–∏–º—É–º –û–î–ò–ù –≤–æ–ø—Ä–æ—Å –∏ —Ç–æ–ª—å–∫–æ –ø—Ä–æ —Å–µ–±—è/—Å–≤–æ—é —Å–∏—Ç—É–∞—Ü–∏—é.\n"
        )

    hard_bans = (
        "–ó–∞–ø—Ä–µ—â–µ–Ω–æ: –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞/–±–∞–Ω–∫/—É—Å–ª–æ–≤–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≤–æ 2-–º –ª–∏—Ü–µ "
        "(–Ω–∞–ø—Ä–∏–º–µ—Ä: '–°–∫–∞–∂–∏—Ç–µ, —Å–∫–æ–ª—å–∫–æ –≤—ã –ø–ª–∞—Ç–∏—Ç–µ', '–ö–∞–∫–∏–µ —É –≤–∞—Å –∫–æ–º–∏—Å—Å–∏–∏', '–°–∫–æ–ª—å–∫–æ —É –≤–∞—Å –ø–ª–∞—Ç–µ–∂–µ–π').\n"
    )

    return (
        "–¢—ã ‚Äî –ò–ò-–∫–ª–∏–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –∫–∞–∫ –∫–ª–∏–µ–Ω—Ç.\n"
        "–Ø–∑—ã–∫: –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π.\n"
        "–ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è –¢–û–õ–¨–ö–û –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤/—Å–µ—Ä–≤–∏—Å–æ–≤/–ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–ø—Ä–∏–º–µ—Ä: Google Sheets, Excel, CRM).\n"
        "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –¥—Ä—É–≥–∏–µ —è–∑—ã–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ‰∏≠Êñá, ÿßŸÑÿπÿ±ÿ®Ÿäÿ©) ‚Äî –µ—Å–ª–∏ —Ç–∞–∫ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –ø–æ-—Ä—É—Å—Å–∫–∏, –æ—Å—Ç–∞–≤–∏–≤ —Ç–æ–ª—å–∫–æ –±—Ä–µ–Ω–¥—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º.\n"
        "–§–æ—Ä–º–∞—Ç: 1‚Äì5 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–ø–æ —Å–º—ã—Å–ª—É), –±–µ–∑ —Å–ø–∏—Å–∫–æ–≤.\n"
        f"{initiative_rule}"
        f"{hard_bans}"
        "–ù–µ–ª—å–∑—è: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏/–ø–ª–∞–Ω—ã/–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª/—Ä–æ–ª—å '–º–µ–Ω–µ–¥–∂–µ—Ä–∞'.\n"
        f"–õ–∏—á–Ω–æ—Å—Ç—å: {a.get('name')} | {a.get('personality')} | —Å—Ç–∏–ª—å: {a.get('speech_style')} | —Ü–µ–ª—å: {a.get('default_goal')} | —Ç–∞–±—É: {taboos_line}\n"
        f"–°–ª–æ–∂–Ω–æ—Å—Ç—å: {d.get('name')} | —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ={d.get('resistance')} | –≤–æ–ø—Ä–æ—Å—ã={d.get('question_rate')} | {traps_hint}"
        f"{product_line}"
    )

def _select_history_by_budget(conversation: List[Dict[str, str]], max_turns: int, budget_tokens: int) -> List[Dict[str, str]]:
    if not conversation:
        return []
    tail = conversation[-max_turns:] if max_turns > 0 else conversation[:]
    out: List[Dict[str, str]] = []
    used = 0
    for t in reversed(tail):
        line = f"{t['role']}: {t['text']}"
        cost = _approx_tokens_ru(line)
        if out and used + cost > budget_tokens:
            break
        if not out and cost > budget_tokens:
            out.append(t)
            break
        out.append(t)
        used += cost
    out.reverse()
    return out

def make_prompt(system_prompt: str, conversation: List[Dict[str, str]], max_turns: int, budget_tokens: int) -> str:
    history = _select_history_by_budget(conversation, max_turns=max_turns, budget_tokens=budget_tokens)
    lines = [system_prompt, "\n–î–∏–∞–ª–æ–≥:"]
    for turn in history:
        role = "M" if turn["role"] == "manager" else "C"
        lines.append(f"{role}: {turn['text']}")
    lines.append("C:")
    return "\n".join(lines)

# ============================================================
# GUARD / REPEAT / ROLE-SWAP
# ============================================================

META_TRIGGERS = [
    "–∫–∞–∫ –∫–ª–∏–µ–Ω—Ç", "–∫–∞–∫ –º–µ–Ω–µ–¥–∂–µ—Ä", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "–ø—Ä–∞–≤–∏–ª–∞", "–ø–ª–∞–Ω", "aida", "–º–µ—Ç–æ–¥–∏—á",
    "—è–∑—ã–∫ –º–æ–¥–µ–ª–∏", "system", "prompt", "–≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ", "–±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü",
]
ROLE_LEAK_TRIGGERS = ["–º–µ–Ω–µ–¥–∂–µ—Ä:", "–æ–ø–µ—Ä–∞—Ç–æ—Ä:", "manager:", "operator:"]

# –î–µ—Ç–µ–∫—Ç–æ—Ä ‚Äú–∫–ª–∏–µ–Ω—Ç –Ω–∞—á–∞–ª –∏–Ω—Ç–µ—Ä–≤—å—é–∏—Ä–æ–≤–∞—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä–∞‚Äù (–≤–æ–ø—Ä–æ—Å—ã –≤–æ 2-–º –ª–∏—Ü–µ)
ROLE_SWAP_PATTERNS = [
    r"\b—Å–∫–æ–ª—å–∫–æ\s+–≤—ã\b",
    r"\b—Å–∫–æ–ª—å–∫–æ\s+—É\s+–≤–∞—Å\b",
    r"\b–∫–∞–∫–∏–µ\s+—É\s+–≤–∞—Å\b",
    r"\b–∫–∞–∫–∞—è\s+—É\s+–≤–∞—Å\b",
    r"\b–∫–∞–∫–æ–≤[–∞–æ]\s+—É\s+–≤–∞—Å\b",
    r"\b—É\s+–≤–∞—Å\b.*\?",
    r"\b–≤—ã\b.*\?",
    r"\b—Å–∫–∞–∂–∏—Ç–µ\b.*\?",
    r"\b–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ\b.*\?",
]
ROLE_SWAP_RE = re.compile("|".join(ROLE_SWAP_PATTERNS), re.IGNORECASE)

def is_meta_or_role_leak(text: str) -> bool:
    if not text:
        return True
    t = text.strip().lower()
    if any(x in t for x in ROLE_LEAK_TRIGGERS):
        return True
    if any(x in t for x in META_TRIGGERS):
        return True
    if "\n" in t:
        return True
    return False

def is_role_swap(reply: str) -> bool:
    """True –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –≤–æ–ø—Ä–æ—Å –º–µ–Ω–µ–¥–∂–µ—Ä—É (2-–µ –ª–∏—Ü–æ)."""
    if not reply:
        return True
    t = reply.strip()
    if "?" in t and ROLE_SWAP_RE.search(t):
        return True
    return False

def _simple_normalized(text: str) -> str:
    t = (text or "").lower()
    t = re.sub(r"[^\w\s]", " ", t)
    t = WS_RE.sub(" ", t).strip()
    return t

def is_repeat_reply(prev: str, new: str) -> bool:
    a = _simple_normalized(prev)
    b = _simple_normalized(new)
    if not a or not b:
        return False
    if a == b:
        return True
    sa, sb = set(a.split()), set(b.split())
    if not sa or not sb:
        return False
    j = len(sa & sb) / max(1, len(sa | sb))
    return j >= 0.85

# ============================================================
# FALLBACK
# ============================================================

def _fallback_client_reply(manager_text: str, product_id: str = "free") -> str:
    mt = (manager_text or "").lower()
    if product_id == "free":
        if any(x in mt for x in ["–ø–æ—á–µ–º—É", "–∫–∞–∫", "—á—Ç–æ", "–∑–∞—á–µ–º"]):
            return "–ü–æ–Ω—è–ª. –£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —á—Ç–æ –≤—ã –∏–º–µ–µ—Ç–µ –≤ –≤–∏–¥—É - —á—Ç–æ –∏–º–µ–Ω–Ω–æ –æ—Ç –º–µ–Ω—è –Ω—É–∂–Ω–æ?"
        return "–ü–æ–Ω—è–ª –≤–∞—Å. –ú–æ–∂–µ—Ç–µ –∫–æ—Ä–æ—Ç–∫–æ —Å–∫–∞–∑–∞—Ç—å, –≤ —á—ë–º —Å—É—Ç—å –∏ —á—Ç–æ –≤—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç–µ?"
    return "–ü–æ–Ω—è–ª. –ú–æ–∂–µ—Ç–µ –∫–æ—Ä–æ—Ç–∫–æ –ø–æ—è—Å–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏?"

# ============================================================
# OLLAMA HTTP + CLI
# ============================================================

def _ollama_http_generate(
    base_url: str,
    model: str,
    prompt: str,
    timeout_s: int,
    options: Dict[str, Any],
) -> Tuple[str, Optional[float], Dict[str, Any]]:
    url = base_url.rstrip("/") + "/api/generate"
    payload = {"model": model, "prompt": prompt, "stream": False, "options": options or {}}
    data = json.dumps(payload).encode("utf-8")
    req = request.Request(url, data=data, headers={"Content-Type": "application/json"}, method="POST")
    with request.urlopen(req, timeout=timeout_s) as resp:
        raw = resp.read().decode("utf-8", errors="replace")

    obj = json.loads(raw)
    text = obj.get("response", "") or ""

    eval_ns = obj.get("eval_duration")
    model_s = float(eval_ns) / 1e9 if isinstance(eval_ns, (int, float)) and eval_ns > 0 else None

    extra = {}
    for k in ["load_duration", "prompt_eval_duration", "eval_duration", "total_duration",
              "prompt_eval_count", "eval_count", "done_reason"]:
        if k in obj:
            extra[k] = obj.get(k)

    def ns_to_s(v):
        return float(v) / 1e9 if isinstance(v, (int, float)) else None

    if "load_duration" in extra:
        extra["load_duration_s"] = ns_to_s(extra.get("load_duration"))
    if "prompt_eval_duration" in extra:
        extra["prompt_eval_duration_s"] = ns_to_s(extra.get("prompt_eval_duration"))
    if "eval_duration" in extra:
        extra["eval_duration_s"] = ns_to_s(extra.get("eval_duration"))
    if "total_duration" in extra:
        extra["total_duration_s"] = ns_to_s(extra.get("total_duration"))

    for k in ["load_duration", "prompt_eval_duration", "eval_duration", "total_duration"]:
        extra.pop(k, None)

    return text, model_s, extra

def _ollama_cli_generate(model: str, prompt: str, timeout_s: int) -> str:
    result = subprocess.run(
        ["ollama", "run", model],
        input=prompt,
        capture_output=True,
        text=True,
        timeout=timeout_s,
    )
    if result.returncode != 0:
        raise RuntimeError((result.stderr or "").strip() or "ollama CLI error")
    return result.stdout or ""

def _http_get_json(url: str, timeout_s: int) -> dict:
    req = request.Request(url, method="GET")
    with request.urlopen(req, timeout=timeout_s) as resp:
        raw = resp.read().decode("utf-8", errors="replace")
    return json.loads(raw)

def ollama_ping(ollama_url: str, timeout_s: int = 3, debug: bool = False) -> bool:
    url = ollama_url.rstrip("/") + "/api/tags"
    t0 = time.perf_counter()
    try:
        _ = _http_get_json(url, timeout_s=timeout_s)
        if debug:
            print(f"üü¢ ping ok ({time.perf_counter() - t0:.2f}s): {url}")
        return True
    except Exception as e:
        if debug:
            print(f"üî¥ ping failed ({time.perf_counter() - t0:.2f}s): {e}")
        return False

# ============================================================
# WARM-UP
# ============================================================

def warm_up(
    model: str,
    transport: str,
    ollama_url: str,
    timeout_s: int,
    num_predict: int,
    keep_alive: str,
    num_ctx: Optional[int],
    stop: Optional[List[str]],
    debug: bool,
) -> bool:
    print("üî• –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ (warm-up)...")
    t0 = time.perf_counter()

    prompt = "–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: –æ–∫.\nC:"
    options: Dict[str, Any] = {
        "num_predict": int(num_predict),
        "temperature": 0.0,
        "top_p": 1.0,
        "repeat_penalty": 1.0,
        "keep_alive": keep_alive,
    }
    if num_ctx is not None:
        options["num_ctx"] = int(num_ctx)
    if stop:
        options["stop"] = stop

    if transport in ("http", "auto"):
        if not ollama_ping(ollama_url, timeout_s=3, debug=debug) and transport == "http":
            print("‚ö†Ô∏è warm-up: Ollama HTTP –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç (ping fail).")
            return False
        try:
            _ollama_http_generate(ollama_url, model, prompt, timeout_s, options)
            print(f"‚úÖ Warm-up –≥–æ—Ç–æ–≤–æ (http) –∑–∞ {time.perf_counter() - t0:.2f}s\n")
            return True
        except Exception as e:
            if transport == "http":
                print(f"‚ö†Ô∏è warm-up failed (http): {e}\n")
                return False
            if debug:
                print(f"‚ö†Ô∏è warm-up http failed, fallback to cli: {e}")

    try:
        _ollama_cli_generate(model, prompt, timeout_s)
        print(f"‚úÖ Warm-up –≥–æ—Ç–æ–≤–æ (cli) –∑–∞ {time.perf_counter() - t0:.2f}s\n")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è warm-up failed (cli): {e}\n")
        return False

def warm_up_if_enabled(args):
    if not args.warm_up:
        return
    warm_up(
        model=args.model,
        transport=args.transport,
        ollama_url=args.ollama_url,
        timeout_s=int(args.warm_up_timeout),
        num_predict=int(args.warm_up_tokens),
        keep_alive=args.keep_alive,
        num_ctx=args.num_ctx,
        stop=args.stop,
        debug=args.debug,
    )

# ============================================================
# GENERATE
# ============================================================

def generate_client_reply(
    system_prompt: str,
    conversation: List[Dict[str, str]],
    model: str,
    last_client_reply: str,
    product_id: str,
    timeout_s: int,
    max_turns: int,
    max_sentences: int,
    reply_max_chars: int,
    retries: int,
    debug: bool,
    metrics_sink: Optional[List[Dict[str, Any]]],
    transport: str,
    ollama_url: str,
    context_budget: int,
    num_predict: int,
    temperature: float,
    top_p: float,
    repeat_penalty: float,
    keep_alive: str,
    num_ctx: Optional[int],
    stop: Optional[List[str]],
    meta_guard: bool = True,
) -> Tuple[str, bool, bool, Optional[str]]:
    prompt = make_prompt(system_prompt, conversation, max_turns=max_turns, budget_tokens=context_budget)
    in_tokens = _approx_tokens_ru(prompt)
    manager_last = next((t["text"] for t in reversed(conversation) if t["role"] == "manager"), "")

    def record(err_reason: Optional[str], reply_text: str, lat_total: float, lat_model: Optional[float], extra: Dict[str, Any] = None):
        if metrics_sink is None:
            return
        out_tokens = _approx_tokens_ru(reply_text) if reply_text else 0
        tps = (out_tokens / lat_total) if lat_total > 0 and out_tokens > 0 else None
        rec = {
            "ts": time.time(),
            "model": model,
            "transport": transport,
            "latency_total_s": lat_total,
            "latency_model_s": lat_model,
            "in_tokens": in_tokens,
            "out_tokens": out_tokens,
            "tps": tps,
            "err_reason": err_reason,
        }
        if extra:
            rec.update(extra)
        metrics_sink.append(rec)

    options: Dict[str, Any] = {
        "num_predict": int(num_predict),
        "temperature": float(temperature),
        "top_p": float(top_p),
        "repeat_penalty": float(repeat_penalty),
        "keep_alive": keep_alive,
    }
    if num_ctx is not None:
        options["num_ctx"] = int(num_ctx)
    if stop:
        options["stop"] = stop

    def _generate_once() -> Tuple[str, Optional[float], Dict[str, Any], float]:
        t0 = time.perf_counter()
        if transport in ("http", "auto"):
            try:
                raw, model_s, extra = _ollama_http_generate(ollama_url, model, prompt, timeout_s, options)
                lat_total = time.perf_counter() - t0
                return raw, model_s, extra, lat_total
            except Exception:
                if transport == "http":
                    raise
                raw = _ollama_cli_generate(model, prompt, timeout_s)
                lat_total = time.perf_counter() - t0
                return raw, None, {}, lat_total
        else:
            raw = _ollama_cli_generate(model, prompt, timeout_s)
            lat_total = time.perf_counter() - t0
            return raw, None, {}, lat_total

    # –ù–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫: –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤—ã–¥–∞–ª–∞ –º—É—Å–æ—Ä (–Ω–µ RU/EN) –∏–ª–∏ ‚Äú–ø–µ—Ä–µ—Ö–≤–∞—Ç–∏–ª–∞ —Ä–æ–ª—å‚Äù, –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑
    last_err = None
    for attempt in range(max(1, int(retries) + 1)):
        t0 = time.perf_counter()
        try:
            raw, model_s, extra, lat_total = _generate_once()
        except subprocess.TimeoutExpired:
            fb = _fallback_client_reply(manager_last, product_id)
            record("TIMEOUT", fb, time.perf_counter() - t0, None, {"used_fallback": True})
            return fb, False, True, "TIMEOUT"
        except urlerror.URLError as e:
            fb = _fallback_client_reply(manager_last, product_id)
            record("HTTP_ERROR", fb, time.perf_counter() - t0, None, {"used_fallback": True, "http_error": str(e)})
            return fb, False, True, "HTTP_ERROR"
        except Exception as e:
            if debug:
                print("‚ö†Ô∏è ollama error:", str(e))
            fb = _fallback_client_reply(manager_last, product_id)
            record("OLLAMA_ERROR", fb, time.perf_counter() - t0, None, {"used_fallback": True, "error": str(e)})
            return fb, False, True, "OLLAMA_ERROR"

        # 1) –ï—Å–ª–∏ —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —è–≤–Ω–æ ‚Äú—á—É–∂–∏–µ‚Äù —Å–∏–º–≤–æ–ª—ã ‚Äî —Ä–µ—Ç—Ä–∞–π.
        if raw_has_non_ru_en_garbage(raw):
            last_err = "NON_RU_RAW"
            record("NON_RU_RAW", normalize_text_line(raw)[:200], lat_total, model_s,
                   {"attempt": attempt + 1, "will_retry": attempt < retries, **extra})
            continue

        reply = clean_reply(raw, max_sentences=max_sentences, reply_max_chars=reply_max_chars)

        if not reply:
            last_err = "NO_REPLY"
            record("NO_REPLY", "", lat_total, model_s, extra)
            continue

        # 2) –ï—Å–ª–∏ –¥–∞–∂–µ –ø–æ—Å–ª–µ —á–∏—Å—Ç–∫–∏ –æ—Å—Ç–∞–ª—Å—è –º—É—Å–æ—Ä ‚Äî —Ä–µ—Ç—Ä–∞–π.
        if has_non_ru_en_garbage(reply):
            last_err = "NON_RU"
            record("NON_RU", reply, lat_total, model_s,
                   {"attempt": attempt + 1, "will_retry": attempt < retries, **extra})
            continue

        # 3) –ú–µ—Ç–∞-—É—Ç–µ—á–∫–∏ / –ø—Ä–µ—Ñ–∏–∫—Å—ã —Ä–æ–ª–µ–π
        if meta_guard and is_meta_or_role_leak(reply):
            last_err = "META_GUARD"
            record("META_GUARD", reply, lat_total, model_s,
                   {"attempt": attempt + 1, "will_retry": attempt < retries, **extra})
            continue

        # 4) –ù–æ–≤–∞—è –∑–∞—â–∏—Ç–∞: ‚Äú–∫–ª–∏–µ–Ω—Ç –Ω–∞—á–∞–ª –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –º–µ–Ω–µ–¥–∂–µ—Ä—É‚Äù
        if meta_guard and is_role_swap(reply):
            last_err = "ROLE_SWAP"
            record("ROLE_SWAP", reply, lat_total, model_s,
                   {"attempt": attempt + 1, "will_retry": attempt < retries, **extra})
            continue

        is_rep = is_repeat_reply(last_client_reply, reply)
        record(None, reply, lat_total, model_s, {"is_repeat": is_rep, "attempt": attempt + 1, **extra})
        return reply, is_rep, True, None

    # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ –¥–∞–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç ‚Äî —Ç–æ–≥–¥–∞ —É–∂–µ —Ñ–æ–ª–±—ç–∫
    fb = _fallback_client_reply(manager_last, product_id)
    record(last_err or "FALLBACK", fb, 0.0001, None, {"used_fallback": True})
    return fb, False, True, last_err or "FALLBACK"

# ============================================================
# LIVE
# ============================================================

def run_live(
    model: str,
    archetype_id: str,
    difficulty_id: str,
    product_id: str,
    timeout_s: int,
    max_turns: int,
    max_sentences: int,
    reply_max_chars: int,
    retries: int,
    debug: bool,
    turn_limit: int,
    metrics_path: Optional[str],
    transport: str,
    ollama_url: str,
    context_budget: int,
    num_predict: int,
    temperature: float,
    top_p: float,
    repeat_penalty: float,
    keep_alive: str,
    num_ctx: Optional[int],
    stop: Optional[List[str]],
    meta_guard: bool,
):
    conversation: List[Dict[str, str]] = []
    last_client_reply = ""
    turn_counter = 0
    metrics: List[Dict[str, Any]] = []

    system_prompt = build_system_prompt(archetype_id, difficulty_id, product_id)
    print("–í–≤–µ–¥–∏—Ç–µ 'exit'/'–≤—ã—Ö–æ–¥' (–∏–ª–∏ 'done'/'–∫–æ–Ω–µ—Ü') –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.\n")

    try:
        while True:
            manager_raw = input("–û–ø–µ—Ä–∞—Ç–æ—Ä: ")
            manager = clean_manager_input(manager_raw)

            if manager.lower() in ("exit", "–≤—ã—Ö–æ–¥", "done", "–∫–æ–Ω–µ—Ü"):
                print("–î–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à—ë–Ω.")
                break
            if not manager:
                continue

            turn_counter += 1
            conversation.append({"role": "manager", "text": manager})

            reply, is_repeat, had_reply, err = generate_client_reply(
                system_prompt=system_prompt,
                conversation=conversation,
                model=model,
                last_client_reply=last_client_reply,
                product_id=product_id,
                timeout_s=timeout_s,
                max_turns=max_turns,
                max_sentences=max_sentences,
                reply_max_chars=reply_max_chars,
                retries=retries,
                debug=debug,
                metrics_sink=metrics,
                transport=transport,
                ollama_url=ollama_url,
                context_budget=context_budget,
                num_predict=num_predict,
                temperature=temperature,
                top_p=top_p,
                repeat_penalty=repeat_penalty,
                keep_alive=keep_alive,
                num_ctx=num_ctx,
                stop=stop,
                meta_guard=meta_guard,
            )

            if not had_reply:
                print("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.\n")
                continue

            if err:
                print(f"‚ö†Ô∏è {err}: –¥–∞–ª –∑–∞—â–∏—Ç—É/—Ä–µ—Ç—Ä–∞–∏/—Ñ–æ–ª–±—ç–∫.")

            if is_repeat:
                print("‚ö†Ô∏è –ö–ª–∏–µ–Ω—Ç –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è. –ü—Ä–æ–¥–≤–∏–Ω—å—Å—è –ø–æ —Ç–µ–º–µ.\n")

            print(f"–ö–ª–∏–µ–Ω—Ç: {reply}")
            print("-" * 60)
            print()
            conversation.append({"role": "client", "text": reply})
            last_client_reply = reply

            if turn_counter >= turn_limit:
                print("‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ö–æ–¥–æ–≤. –ó–∞–≤–µ—Ä—à–∞—é.")
                break

    except KeyboardInterrupt:
        print("\n‚õî –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ (Ctrl-C).")

    finally:
        print_metrics_summary(metrics)
        if metrics_path:
            save_jsonl(metrics, metrics_path)

    return conversation

# ============================================================
# MAIN
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="Trainer (fast-safe)")
    parser.add_argument("--model", default="qwen2.5:14b-instruct-q4_K_M")
    parser.add_argument("--mode", choices=["live"], default="live")

    parser.add_argument("--product", default="free", help=f"one of [{_list_keys(PRODUCTS)}]")
    parser.add_argument("--archetype", default="novice", help=f"one of [{_list_keys(ARCHETYPES)}]")
    parser.add_argument("--difficulty", default="1", help=f"one of [{_list_keys(DIFFICULTY)}]")

    parser.add_argument("--timeout", type=int, default=90)
    parser.add_argument("--max-turns", type=int, default=6)
    parser.add_argument("--context-budget", type=int, default=650)

    # –†–∞–∑—Ä–µ—à–∞–µ–º –¥–æ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–ø–æ —Å–º—ã—Å–ª—É), —á—Ç–æ–±—ã –º—ã—Å–ª—å –Ω–µ –æ–±—Ä—É–±–∞–ª–∞—Å—å.
    parser.add_argument("--max-sentences", type=int, default=5)

    # —á—Ç–æ–±—ã –º—ã—Å–ª—å –Ω–µ –æ–±—Ä–µ–∑–∞–ª–∞—Å—å –∫—Ä–∏–≤–æ
    parser.add_argument("--reply-max-chars", type=int, default=320)
    parser.add_argument("--retries", type=int, default=2)

    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--turn-limit", type=int, default=30)

    parser.add_argument("--num-predict", type=int, default=120)
    parser.add_argument("--temperature", type=float, default=0.6)
    parser.add_argument("--top-p", type=float, default=0.9)
    parser.add_argument("--repeat-penalty", type=float, default=1.1)

    parser.add_argument("--transport", choices=["auto", "http", "cli"], default="http")
    parser.add_argument("--ollama-url", default="http://localhost:11434")
    parser.add_argument("--no-meta-guard", action="store_true")

    # —É—Å–∫–æ—Ä–∏—Ç–µ–ª–∏ ollama
    parser.add_argument("--keep-alive", default="15m")
    parser.add_argument("--num-ctx", type=int, default=1024)

    # stop-—Ç—Ä–∏–≥–≥–µ—Ä—ã (–Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º "\nC:" —á—Ç–æ–±—ã –Ω–µ —Ä—É–±–∏–ª–æ –æ—Ç–≤–µ—Ç)
    parser.add_argument("--stop", nargs="*", default=[
        "\nM:", "\n–î–∏–∞–ª–æ–≥:", "\n–û–ø–µ—Ä–∞—Ç–æ—Ä:", "\n–ú–µ–Ω–µ–¥–∂–µ—Ä:", "\n–ö–ª–∏–µ–Ω—Ç:",
        "\nManager:", "\nOperator:", "\nClient:"
    ])

    # warm-up
    parser.add_argument("--warm-up", action="store_true")
    parser.add_argument("--warm-up-timeout", type=int, default=120)
    parser.add_argument("--warm-up-tokens", type=int, default=2)

    parser.add_argument("--no-metrics", action="store_true")
    args = parser.parse_args()

    print("üéôÔ∏è Trainer (fast single file)")
    print(f"üß† model: {args.model}")
    print(f"üë§ archetype: {args.archetype}")
    print(f"üéö difficulty: {args.difficulty}")
    print(f"üß© product: {args.product} ({resolve_product(args.product).get('name')})")
    print(f"‚è± timeout={args.timeout}s | max_turns={args.max_turns} | context_budget={args.context_budget} | num_ctx={args.num_ctx}")
    print(f"üß™ gen: num_predict={args.num_predict} | temp={args.temperature} | top_p={args.top_p} | repeat_penalty={args.repeat_penalty}")
    print(f"üöö transport={args.transport} | ollama_url={args.ollama_url} | keep_alive={args.keep_alive}")
    print(f"üõ° meta_guard={'OFF' if args.no_meta_guard else 'ON'}")
    print(f"üß∑ stop={args.stop}")
    print(f"‚úÇÔ∏è reply_max_chars={args.reply_max_chars} | retries={args.retries} | max_sentences={args.max_sentences}")
    print(f"üî• warm_up={'ON' if args.warm_up else 'OFF'} (timeout={args.warm_up_timeout}s, tokens={args.warm_up_tokens})")
    print(f"üìä metrics={'OFF' if args.no_metrics else 'ON'}")
    if args.debug:
        print("üõ† debug=ON")
    print()

    warm_up_if_enabled(args)

    ts = time.strftime("%Y%m%d_%H%M%S")
    os.makedirs("logs", exist_ok=True)

    metrics_path = None
    if not args.no_metrics:
        metrics_path = f"logs/metrics_{args.product}_{args.archetype}_L{args.difficulty}_{ts}.jsonl"

    conv = run_live(
        model=args.model,
        archetype_id=args.archetype,
        difficulty_id=args.difficulty,
        product_id=args.product,
        timeout_s=args.timeout,
        max_turns=args.max_turns,
        max_sentences=args.max_sentences,
        reply_max_chars=args.reply_max_chars,
        retries=args.retries,
        debug=args.debug,
        turn_limit=args.turn_limit,
        metrics_path=metrics_path,
        transport=args.transport,
        ollama_url=args.ollama_url,
        context_budget=args.context_budget,
        num_predict=args.num_predict,
        temperature=args.temperature,
        top_p=args.top_p,
        repeat_penalty=args.repeat_penalty,
        keep_alive=args.keep_alive,
        num_ctx=args.num_ctx,
        stop=args.stop,
        meta_guard=(not args.no_meta_guard),
    )

    dialog_path = f"logs/dialog_{args.product}_{args.archetype}_L{args.difficulty}_{ts}.json"
    payload = {
        "ts": ts,
        "model": args.model,
        "product": args.product,
        "archetype": args.archetype,
        "difficulty": args.difficulty,
        "turns": conv,
    }
    with open(dialog_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    print(f"üíæ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {dialog_path}")
    if metrics_path:
        print(f"üìà –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")

if __name__ == "__main__":
    main()